{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 3 Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will focus on healthcare. This data set is made available by MIT. It contains data about 9,026 heartbeat measurements. Each row represents a single measurement (captured on a timeline). There are a total of 80 data points (columns). This is a multiclass classification task: predict whether the measurement represents a normal heartbeat or other anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "You will use the **hearbeat_cleaned.csv** data set for this assignment. Each row represents a single measurement. Columns labeled as T1 from T80 are the time steps on the timeline (there are 80 time steps, each time step has only one measurement). \n",
    "\n",
    "The last column is the target variable. It shows the label (category) of the measurement as follows:<br>\n",
    "0 = Normal<br>\n",
    "1 = Supraventricular premature beat<br>\n",
    "2 = Premature ventricular contraction<br>\n",
    "3 = Fusion of ventricular and normal beat<br>\n",
    "4 = Unclassifiable beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the data set **hearbeat_cleaned.csv** to predict the column called **Target**. The input variables are columns labeled as **T1 to T80**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission:\n",
    "\n",
    "Please save and submit this Jupyter notebook file. The correctness of the code matters for your grade. **Readability and organization of your code is also important.** You may lose points for submitting unreadable/undecipherable code. Therefore, use markdown cells to create sections, and use comments where necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data (1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"heartbeat_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7960, 81)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>...</th>\n",
       "      <th>T72</th>\n",
       "      <th>T73</th>\n",
       "      <th>T74</th>\n",
       "      <th>T75</th>\n",
       "      <th>T76</th>\n",
       "      <th>T77</th>\n",
       "      <th>T78</th>\n",
       "      <th>T79</th>\n",
       "      <th>T80</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2260</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0851</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T1     T2     T3      T4      T5      T6      T7      T8      T9  \\\n",
       "0  0.987  0.892  0.461  0.1130  0.1490  0.1900  0.1650  0.1620  0.1470   \n",
       "1  1.000  0.918  0.621  0.1330  0.1050  0.1250  0.1170  0.0898  0.0703   \n",
       "2  1.000  0.751  0.143  0.1040  0.0961  0.0519  0.0442  0.0416  0.0364   \n",
       "3  1.000  0.740  0.235  0.0464  0.0722  0.0567  0.0103  0.0155  0.0284   \n",
       "4  1.000  0.833  0.309  0.0191  0.1010  0.1200  0.1040  0.0874  0.0765   \n",
       "\n",
       "      T10  ...     T72     T73     T74     T75    T76     T77     T78    T79  \\\n",
       "0  0.1380  ...  0.1970  0.1970  0.1960  0.2030  0.201  0.1990  0.2010  0.205   \n",
       "1  0.0781  ...  0.1950  0.1910  0.1520  0.1720  0.207  0.2110  0.2070  0.207   \n",
       "2  0.0857  ...  0.2260  0.2420  0.2440  0.2860  0.468  0.8160  0.9770  0.452   \n",
       "3  0.0155  ...  0.0851  0.0747  0.0515  0.0593  0.067  0.0361  0.1210  0.451   \n",
       "4  0.0765  ...  0.2050  0.4210  0.8030  0.9510  0.467  0.0000  0.0519  0.082   \n",
       "\n",
       "      T80  Target  \n",
       "0  0.2080       0  \n",
       "1  0.1720       0  \n",
       "2  0.0519       0  \n",
       "3  0.8690       0  \n",
       "4  0.0628       0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Target']\n",
    "x = data.drop('Target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target variables need to be an array with integer type\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "train_y = train_y.astype(np.int32)\n",
    "test_y = test_y.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 4, 4, 4, 0, 2, 4, 2, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the first 10 values of the train_y data set\n",
    "train_y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert input variables to a 2-D array with float data type\n",
    "train_x= np.array(train_x)\n",
    "test_x= np.array(test_x)\n",
    "\n",
    "train_x = train_x.astype(np.float32)\n",
    "test_x = test_x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.    , 0.828 , 0.648 , ..., 0.227 , 0.426 , 0.492 ],\n",
       "       [0.972 , 0.899 , 0.551 , ..., 0.193 , 0.172 , 0.178 ],\n",
       "       [1.    , 0.519 , 0.498 , ..., 0.121 , 0.107 , 0.111 ],\n",
       "       ...,\n",
       "       [1.    , 0.864 , 0.17  , ..., 0.128 , 0.132 , 0.136 ],\n",
       "       [0.953 , 0.838 , 0.38  , ..., 0.137 , 0.0299, 0.0769],\n",
       "       [1.    , 0.587 , 0.627 , ..., 0.138 , 0.169 , 0.164 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras expects a different input format:\n",
    "#Data needs to have 3 dimensions\n",
    "\n",
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572, 80, 1), (5572,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.    ],\n",
       "        [0.828 ],\n",
       "        [0.648 ],\n",
       "        ...,\n",
       "        [0.227 ],\n",
       "        [0.426 ],\n",
       "        [0.492 ]],\n",
       "\n",
       "       [[0.972 ],\n",
       "        [0.899 ],\n",
       "        [0.551 ],\n",
       "        ...,\n",
       "        [0.193 ],\n",
       "        [0.172 ],\n",
       "        [0.178 ]],\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.519 ],\n",
       "        [0.498 ],\n",
       "        ...,\n",
       "        [0.121 ],\n",
       "        [0.107 ],\n",
       "        [0.111 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.864 ],\n",
       "        [0.17  ],\n",
       "        ...,\n",
       "        [0.128 ],\n",
       "        [0.132 ],\n",
       "        [0.136 ]],\n",
       "\n",
       "       [[0.953 ],\n",
       "        [0.838 ],\n",
       "        [0.38  ],\n",
       "        ...,\n",
       "        [0.137 ],\n",
       "        [0.0299],\n",
       "        [0.0769]],\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.587 ],\n",
       "        [0.627 ],\n",
       "        ...,\n",
       "        [0.138 ],\n",
       "        [0.169 ],\n",
       "        [0.164 ]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the baseline (0.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "dummy_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Train Accuracy: 0.5759152907394114\n"
     ]
    }
   ],
   "source": [
    "#Baseline Train Accuracy\n",
    "dummy_train_pred = dummy_clf.predict(train_x)\n",
    "\n",
    "baseline_train_acc = accuracy_score(train_y, dummy_train_pred)\n",
    "\n",
    "print('Baseline Train Accuracy: {}' .format(baseline_train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy: 0.5963149078726968\n"
     ]
    }
   ],
   "source": [
    "#Baseline Test Accuracy\n",
    "dummy_test_pred = dummy_clf.predict(test_x)\n",
    "\n",
    "baseline_test_acc = accuracy_score(test_y, dummy_test_pred)\n",
    "\n",
    "print('Baseline Test Accuracy: {}' .format(baseline_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a cross-sectional (i.e., a regular) Neural Network model using Keras (with only one hidden layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Flatten(input_shape=[80, 1]),\n",
    "    keras.layers.Dense(80, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "175/175 [==============================] - 1s 2ms/step - loss: 0.6656 - accuracy: 0.7812 - val_loss: 0.4542 - val_accuracy: 0.8597\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.4397 - accuracy: 0.8677 - val_loss: 0.5176 - val_accuracy: 0.8547\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.4086 - accuracy: 0.8737 - val_loss: 0.3888 - val_accuracy: 0.8970\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8921 - val_loss: 0.3525 - val_accuracy: 0.8832\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.9024 - val_loss: 0.3207 - val_accuracy: 0.9075\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.3194 - accuracy: 0.9056 - val_loss: 0.2822 - val_accuracy: 0.9234\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2959 - accuracy: 0.9117 - val_loss: 0.2876 - val_accuracy: 0.9221\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.9137 - val_loss: 0.2668 - val_accuracy: 0.9288\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.9203 - val_loss: 0.2954 - val_accuracy: 0.9133\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2701 - accuracy: 0.9178 - val_loss: 0.3458 - val_accuracy: 0.8882\n",
      "Epoch 11/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2631 - accuracy: 0.9203 - val_loss: 0.2529 - val_accuracy: 0.9242\n",
      "Epoch 12/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2479 - accuracy: 0.9268 - val_loss: 0.2613 - val_accuracy: 0.9246\n",
      "Epoch 13/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2427 - accuracy: 0.9268 - val_loss: 0.2359 - val_accuracy: 0.9343\n",
      "Epoch 14/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2330 - accuracy: 0.9295 - val_loss: 0.2512 - val_accuracy: 0.9334\n",
      "Epoch 15/50\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.2275 - accuracy: 0.9318 - val_loss: 0.2451 - val_accuracy: 0.9292\n",
      "Epoch 16/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2245 - accuracy: 0.9296 - val_loss: 0.2415 - val_accuracy: 0.9305\n",
      "Epoch 17/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2182 - accuracy: 0.9343 - val_loss: 0.2419 - val_accuracy: 0.9343\n",
      "Epoch 18/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2130 - accuracy: 0.9340 - val_loss: 0.2498 - val_accuracy: 0.9334\n",
      "Epoch 19/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2125 - accuracy: 0.9358 - val_loss: 0.2384 - val_accuracy: 0.9292\n",
      "Epoch 20/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9388 - val_loss: 0.2331 - val_accuracy: 0.9330\n",
      "Epoch 21/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2032 - accuracy: 0.9350 - val_loss: 0.2310 - val_accuracy: 0.9368\n",
      "Epoch 22/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1988 - accuracy: 0.9356 - val_loss: 0.2930 - val_accuracy: 0.9079\n",
      "Epoch 23/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2091 - accuracy: 0.9322 - val_loss: 0.2513 - val_accuracy: 0.9305\n",
      "Epoch 24/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1940 - accuracy: 0.9381 - val_loss: 0.3534 - val_accuracy: 0.8949\n",
      "Epoch 25/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1915 - accuracy: 0.9397 - val_loss: 0.2318 - val_accuracy: 0.9338\n",
      "Epoch 26/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1882 - accuracy: 0.9424 - val_loss: 0.2533 - val_accuracy: 0.9288\n",
      "Epoch 27/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1956 - accuracy: 0.9381 - val_loss: 0.2364 - val_accuracy: 0.9309\n",
      "Epoch 28/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1835 - accuracy: 0.9424 - val_loss: 0.2486 - val_accuracy: 0.9238\n",
      "Epoch 29/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1824 - accuracy: 0.9399 - val_loss: 0.2254 - val_accuracy: 0.9401\n",
      "Epoch 30/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1813 - accuracy: 0.9424 - val_loss: 0.2360 - val_accuracy: 0.9372\n",
      "Epoch 31/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1797 - accuracy: 0.9426 - val_loss: 0.2311 - val_accuracy: 0.9372\n",
      "Epoch 32/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1788 - accuracy: 0.9435 - val_loss: 0.2273 - val_accuracy: 0.9326\n",
      "Epoch 33/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1759 - accuracy: 0.9463 - val_loss: 0.2247 - val_accuracy: 0.9330\n",
      "Epoch 34/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1716 - accuracy: 0.9454 - val_loss: 0.2312 - val_accuracy: 0.9280\n",
      "Epoch 35/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1738 - accuracy: 0.9444 - val_loss: 0.2363 - val_accuracy: 0.9309\n",
      "Epoch 36/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1679 - accuracy: 0.9451 - val_loss: 0.3617 - val_accuracy: 0.8819\n",
      "Epoch 37/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1734 - accuracy: 0.9445 - val_loss: 0.2566 - val_accuracy: 0.9246\n",
      "Epoch 38/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1598 - accuracy: 0.9487 - val_loss: 0.2155 - val_accuracy: 0.9397\n",
      "Epoch 39/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.9474 - val_loss: 0.2399 - val_accuracy: 0.9347\n",
      "Epoch 40/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1586 - accuracy: 0.9467 - val_loss: 0.2158 - val_accuracy: 0.9393\n",
      "Epoch 41/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1623 - accuracy: 0.9481 - val_loss: 0.2267 - val_accuracy: 0.9422\n",
      "Epoch 42/50\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1570 - accuracy: 0.9472 - val_loss: 0.2219 - val_accuracy: 0.9322\n",
      "Epoch 43/50\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1554 - accuracy: 0.9510 - val_loss: 0.2667 - val_accuracy: 0.9343\n",
      "Epoch 44/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1636 - accuracy: 0.9458 - val_loss: 0.2254 - val_accuracy: 0.9363\n",
      "Epoch 45/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1554 - accuracy: 0.9505 - val_loss: 0.2285 - val_accuracy: 0.9410\n",
      "Epoch 46/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1531 - accuracy: 0.9487 - val_loss: 0.2350 - val_accuracy: 0.9397\n",
      "Epoch 47/50\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.1574 - accuracy: 0.9465 - val_loss: 0.2154 - val_accuracy: 0.9439\n",
      "Epoch 48/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1473 - accuracy: 0.9517 - val_loss: 0.2246 - val_accuracy: 0.9405\n",
      "Epoch 49/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1434 - accuracy: 0.9515 - val_loss: 0.2335 - val_accuracy: 0.9363\n",
      "Epoch 50/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9533 - val_loss: 0.2165 - val_accuracy: 0.9401\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                    validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21651983261108398, 0.9401172399520874]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.22\n",
      "accuracy: 94.01%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a deep cross-sectional (i.e., regular) Neural Network model using Keras (with two or more hidden layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Flatten(input_shape=[80, 1]),\n",
    "    keras.layers.Dense(76, activation='relu'),\n",
    "    keras.layers.Dense(76, activation='relu'),\n",
    "    keras.layers.Dense(76, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "175/175 [==============================] - 3s 6ms/step - loss: 0.5881 - accuracy: 0.8031 - val_loss: 0.4273 - val_accuracy: 0.8668\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.3770 - accuracy: 0.8837 - val_loss: 0.4757 - val_accuracy: 0.8597\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.3319 - accuracy: 0.8984 - val_loss: 0.3048 - val_accuracy: 0.9079\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.3011 - accuracy: 0.9065 - val_loss: 0.3131 - val_accuracy: 0.8890\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.2914 - accuracy: 0.9081 - val_loss: 0.2634 - val_accuracy: 0.9217\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.2677 - accuracy: 0.9140 - val_loss: 0.2624 - val_accuracy: 0.9217\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2656 - accuracy: 0.9151 - val_loss: 0.2606 - val_accuracy: 0.9200\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2351 - accuracy: 0.9270 - val_loss: 0.2512 - val_accuracy: 0.9204\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2363 - accuracy: 0.9279 - val_loss: 0.3154 - val_accuracy: 0.8982\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.2254 - accuracy: 0.9316 - val_loss: 0.2515 - val_accuracy: 0.9313\n",
      "Epoch 11/50\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 0.2165 - accuracy: 0.9291 - val_loss: 0.2204 - val_accuracy: 0.9347\n",
      "Epoch 12/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2218 - accuracy: 0.9302 - val_loss: 0.2363 - val_accuracy: 0.9280\n",
      "Epoch 13/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2147 - accuracy: 0.9323 - val_loss: 0.2179 - val_accuracy: 0.9313\n",
      "Epoch 14/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2029 - accuracy: 0.9356 - val_loss: 0.2193 - val_accuracy: 0.9343\n",
      "Epoch 15/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2094 - accuracy: 0.9338 - val_loss: 0.2116 - val_accuracy: 0.9393\n",
      "Epoch 16/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1915 - accuracy: 0.9370 - val_loss: 0.2082 - val_accuracy: 0.9435\n",
      "Epoch 17/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1874 - accuracy: 0.9406 - val_loss: 0.2286 - val_accuracy: 0.9405\n",
      "Epoch 18/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1967 - accuracy: 0.9388 - val_loss: 0.2386 - val_accuracy: 0.9255\n",
      "Epoch 19/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1880 - accuracy: 0.9402 - val_loss: 0.2078 - val_accuracy: 0.9317\n",
      "Epoch 20/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1719 - accuracy: 0.9462 - val_loss: 0.4073 - val_accuracy: 0.8589\n",
      "Epoch 21/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9341 - val_loss: 0.2248 - val_accuracy: 0.9389\n",
      "Epoch 22/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1883 - accuracy: 0.9381 - val_loss: 0.2555 - val_accuracy: 0.9213\n",
      "Epoch 23/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1760 - accuracy: 0.9467 - val_loss: 0.2040 - val_accuracy: 0.9430\n",
      "Epoch 24/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1832 - accuracy: 0.9397 - val_loss: 0.2619 - val_accuracy: 0.9317\n",
      "Epoch 25/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1696 - accuracy: 0.9465 - val_loss: 0.2175 - val_accuracy: 0.9372\n",
      "Epoch 26/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1653 - accuracy: 0.9454 - val_loss: 0.4257 - val_accuracy: 0.8832\n",
      "Epoch 27/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.2317 - accuracy: 0.9261 - val_loss: 0.2422 - val_accuracy: 0.9200\n",
      "Epoch 28/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1930 - accuracy: 0.9384 - val_loss: 0.2407 - val_accuracy: 0.9317\n",
      "Epoch 29/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1644 - accuracy: 0.9447 - val_loss: 0.2197 - val_accuracy: 0.9368\n",
      "Epoch 30/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1662 - accuracy: 0.9471 - val_loss: 0.2523 - val_accuracy: 0.9305\n",
      "Epoch 31/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1731 - accuracy: 0.9476 - val_loss: 0.2419 - val_accuracy: 0.9363\n",
      "Epoch 32/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1517 - accuracy: 0.9512 - val_loss: 0.2200 - val_accuracy: 0.9359\n",
      "Epoch 33/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1529 - accuracy: 0.9490 - val_loss: 0.2172 - val_accuracy: 0.9422\n",
      "Epoch 34/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1604 - accuracy: 0.9503 - val_loss: 0.2474 - val_accuracy: 0.9359\n",
      "Epoch 35/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1448 - accuracy: 0.9523 - val_loss: 0.2638 - val_accuracy: 0.9347\n",
      "Epoch 36/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1579 - accuracy: 0.9505 - val_loss: 0.3279 - val_accuracy: 0.9033\n",
      "Epoch 37/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1590 - accuracy: 0.9487 - val_loss: 0.2752 - val_accuracy: 0.9238\n",
      "Epoch 38/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1796 - accuracy: 0.9451 - val_loss: 0.2290 - val_accuracy: 0.9351\n",
      "Epoch 39/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1513 - accuracy: 0.9521 - val_loss: 0.2332 - val_accuracy: 0.9397\n",
      "Epoch 40/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1463 - accuracy: 0.9526 - val_loss: 0.2135 - val_accuracy: 0.9439\n",
      "Epoch 41/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1650 - accuracy: 0.9451 - val_loss: 0.2084 - val_accuracy: 0.9456\n",
      "Epoch 42/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1323 - accuracy: 0.9567 - val_loss: 0.2298 - val_accuracy: 0.9380\n",
      "Epoch 43/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1430 - accuracy: 0.9555 - val_loss: 0.2639 - val_accuracy: 0.9414\n",
      "Epoch 44/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1341 - accuracy: 0.9567 - val_loss: 0.2530 - val_accuracy: 0.9330\n",
      "Epoch 45/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1296 - accuracy: 0.9582 - val_loss: 0.2450 - val_accuracy: 0.9405\n",
      "Epoch 46/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1307 - accuracy: 0.9580 - val_loss: 0.2560 - val_accuracy: 0.9376\n",
      "Epoch 47/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1610 - accuracy: 0.9487 - val_loss: 0.2139 - val_accuracy: 0.9443\n",
      "Epoch 48/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1288 - accuracy: 0.9566 - val_loss: 0.2562 - val_accuracy: 0.9472\n",
      "Epoch 49/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1372 - accuracy: 0.9559 - val_loss: 0.2323 - val_accuracy: 0.9447\n",
      "Epoch 50/50\n",
      "175/175 [==============================] - 1s 4ms/step - loss: 0.1258 - accuracy: 0.9614 - val_loss: 0.2806 - val_accuracy: 0.9347\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                    validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.28059840202331543, 0.9346733689308167]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.28\n",
      "accuracy: 93.47%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a LSTM Model (with only one layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.LSTM(75, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 15s 70ms/step - loss: 1.1374 - accuracy: 0.5705 - val_loss: 1.0533 - val_accuracy: 0.5800\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 13s 72ms/step - loss: 1.0773 - accuracy: 0.5774 - val_loss: 0.9958 - val_accuracy: 0.6374\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 12s 69ms/step - loss: 1.0573 - accuracy: 0.5985 - val_loss: 0.9949 - val_accuracy: 0.6248\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 1.0392 - accuracy: 0.6039 - val_loss: 0.9892 - val_accuracy: 0.6348\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.9727 - accuracy: 0.6303 - val_loss: 1.0154 - val_accuracy: 0.6315\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.8198 - accuracy: 0.7105 - val_loss: 0.9298 - val_accuracy: 0.6399\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.6650 - accuracy: 0.7852 - val_loss: 0.5821 - val_accuracy: 0.8178\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.6044 - accuracy: 0.8020 - val_loss: 0.6912 - val_accuracy: 0.7626\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 15s 88ms/step - loss: 0.5904 - accuracy: 0.8087 - val_loss: 0.5047 - val_accuracy: 0.8379\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 15s 86ms/step - loss: 0.5371 - accuracy: 0.8270 - val_loss: 0.6626 - val_accuracy: 0.7680\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 15s 88ms/step - loss: 0.5171 - accuracy: 0.8284 - val_loss: 0.6681 - val_accuracy: 0.7789\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 16s 90ms/step - loss: 0.5026 - accuracy: 0.8333 - val_loss: 0.5704 - val_accuracy: 0.7936\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 15s 87ms/step - loss: 0.4799 - accuracy: 0.8419 - val_loss: 0.4048 - val_accuracy: 0.8643\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 15s 84ms/step - loss: 0.6020 - accuracy: 0.8105 - val_loss: 0.5358 - val_accuracy: 0.8342\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 15s 88ms/step - loss: 0.5004 - accuracy: 0.8405 - val_loss: 0.4194 - val_accuracy: 0.8626\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 14s 82ms/step - loss: 0.4238 - accuracy: 0.8618 - val_loss: 0.3812 - val_accuracy: 0.8760\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 15s 86ms/step - loss: 0.4438 - accuracy: 0.8580 - val_loss: 0.3890 - val_accuracy: 0.8752\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 15s 87ms/step - loss: 0.3811 - accuracy: 0.8846 - val_loss: 0.4667 - val_accuracy: 0.8442\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 15s 85ms/step - loss: 0.3584 - accuracy: 0.8887 - val_loss: 0.3218 - val_accuracy: 0.9062\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.3684 - accuracy: 0.8853 - val_loss: 0.3984 - val_accuracy: 0.8794\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3984287977218628, 0.8793969750404358]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.40\n",
      "accuracy: 87.94%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a deep LSTM Model (with only two layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(76, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.LSTM(76),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 39s 183ms/step - loss: 1.1568 - accuracy: 0.5678 - val_loss: 1.0972 - val_accuracy: 0.5963\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 1.1378 - accuracy: 0.5759 - val_loss: 1.0985 - val_accuracy: 0.5963\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 27s 156ms/step - loss: 1.1224 - accuracy: 0.5759 - val_loss: 1.0596 - val_accuracy: 0.5963\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 1.0829 - accuracy: 0.5750 - val_loss: 1.0141 - val_accuracy: 0.5963\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 29s 168ms/step - loss: 1.0236 - accuracy: 0.5887 - val_loss: 1.0403 - val_accuracy: 0.6152\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 29s 165ms/step - loss: 0.9179 - accuracy: 0.6595 - val_loss: 0.8480 - val_accuracy: 0.7056\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 29s 163ms/step - loss: 0.8637 - accuracy: 0.6874 - val_loss: 0.8087 - val_accuracy: 0.7161\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 29s 164ms/step - loss: 0.8175 - accuracy: 0.7062 - val_loss: 0.7664 - val_accuracy: 0.7257\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 32s 181ms/step - loss: 0.7764 - accuracy: 0.7310 - val_loss: 0.7132 - val_accuracy: 0.7513\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 30s 173ms/step - loss: 0.7508 - accuracy: 0.7459 - val_loss: 0.6762 - val_accuracy: 0.7910\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 29s 167ms/step - loss: 0.6837 - accuracy: 0.7773 - val_loss: 0.6499 - val_accuracy: 0.7902\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 28s 161ms/step - loss: 0.6729 - accuracy: 0.7737 - val_loss: 0.7378 - val_accuracy: 0.7345\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 28s 163ms/step - loss: 0.5634 - accuracy: 0.8225 - val_loss: 0.4352 - val_accuracy: 0.8597\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 28s 161ms/step - loss: 0.4651 - accuracy: 0.8482 - val_loss: 0.3807 - val_accuracy: 0.8748\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 28s 161ms/step - loss: 0.4466 - accuracy: 0.8566 - val_loss: 0.3797 - val_accuracy: 0.8798\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 0.3994 - accuracy: 0.8695 - val_loss: 0.4029 - val_accuracy: 0.8673\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 29s 163ms/step - loss: 0.3988 - accuracy: 0.8684 - val_loss: 0.3512 - val_accuracy: 0.8945\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 29s 165ms/step - loss: 0.3583 - accuracy: 0.8891 - val_loss: 0.3114 - val_accuracy: 0.9091\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 29s 163ms/step - loss: 0.3456 - accuracy: 0.8972 - val_loss: 0.5103 - val_accuracy: 0.8245\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 0.3368 - accuracy: 0.8991 - val_loss: 0.2966 - val_accuracy: 0.9075\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2965945601463318, 0.9074539542198181]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.30\n",
      "accuracy: 90.75%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a GRU Model (with only one layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(75, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 16s 66ms/step - loss: 1.0974 - accuracy: 0.5831 - val_loss: 0.9725 - val_accuracy: 0.6340\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 11s 64ms/step - loss: 0.7552 - accuracy: 0.7387 - val_loss: 0.7489 - val_accuracy: 0.7462\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 0.4859 - accuracy: 0.8410 - val_loss: 0.3816 - val_accuracy: 0.8815\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 0.3791 - accuracy: 0.8835 - val_loss: 0.3149 - val_accuracy: 0.9062\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 0.3341 - accuracy: 0.9013 - val_loss: 0.3009 - val_accuracy: 0.9045\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 0.3086 - accuracy: 0.9045 - val_loss: 0.3133 - val_accuracy: 0.8974\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 11s 62ms/step - loss: 0.2957 - accuracy: 0.9108 - val_loss: 0.2670 - val_accuracy: 0.9183\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 11s 62ms/step - loss: 0.2825 - accuracy: 0.9140 - val_loss: 0.3060 - val_accuracy: 0.9012\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 0.2606 - accuracy: 0.9189 - val_loss: 0.2850 - val_accuracy: 0.9129\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 0.2600 - accuracy: 0.9209 - val_loss: 0.2644 - val_accuracy: 0.9171\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 0.2767 - accuracy: 0.9156 - val_loss: 0.3435 - val_accuracy: 0.8903\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 11s 62ms/step - loss: 0.2998 - accuracy: 0.9018 - val_loss: 0.2575 - val_accuracy: 0.9246\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 10s 59ms/step - loss: 0.2323 - accuracy: 0.9244 - val_loss: 0.2952 - val_accuracy: 0.9054\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 10s 60ms/step - loss: 0.2351 - accuracy: 0.9243 - val_loss: 0.2370 - val_accuracy: 0.9263\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 10s 59ms/step - loss: 0.2209 - accuracy: 0.9311 - val_loss: 0.2250 - val_accuracy: 0.9301\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 10s 59ms/step - loss: 0.2171 - accuracy: 0.9309 - val_loss: 0.2227 - val_accuracy: 0.9309\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 10s 59ms/step - loss: 0.2032 - accuracy: 0.9318 - val_loss: 0.2184 - val_accuracy: 0.9363\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 10s 59ms/step - loss: 0.1997 - accuracy: 0.9314 - val_loss: 0.2521 - val_accuracy: 0.9229\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 10s 60ms/step - loss: 0.1775 - accuracy: 0.9426 - val_loss: 0.2580 - val_accuracy: 0.9200\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 0.1840 - accuracy: 0.9402 - val_loss: 0.1909 - val_accuracy: 0.9426\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1909337192773819, 0.9426298141479492]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.19\n",
      "accuracy: 94.26%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a deep GRU Model (with only two layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(75, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(75),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 33s 134ms/step - loss: 0.9725 - accuracy: 0.6398 - val_loss: 0.5476 - val_accuracy: 0.8220\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 22s 123ms/step - loss: 0.4562 - accuracy: 0.8527 - val_loss: 0.4704 - val_accuracy: 0.8572\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 0.3617 - accuracy: 0.8792 - val_loss: 0.5609 - val_accuracy: 0.7952\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 21s 122ms/step - loss: 0.3260 - accuracy: 0.8993 - val_loss: 0.2877 - val_accuracy: 0.9070\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 22s 123ms/step - loss: 0.2998 - accuracy: 0.9070 - val_loss: 0.2647 - val_accuracy: 0.9196\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 21s 123ms/step - loss: 0.2802 - accuracy: 0.9115 - val_loss: 0.2612 - val_accuracy: 0.9225\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 22s 124ms/step - loss: 0.2593 - accuracy: 0.9219 - val_loss: 0.2521 - val_accuracy: 0.9255\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 23s 129ms/step - loss: 0.2512 - accuracy: 0.9158 - val_loss: 0.2781 - val_accuracy: 0.9049\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 22s 124ms/step - loss: 0.2551 - accuracy: 0.9189 - val_loss: 0.2770 - val_accuracy: 0.9150\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 0.2429 - accuracy: 0.9216 - val_loss: 0.2972 - val_accuracy: 0.9091\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 0.6922 - accuracy: 0.7717 - val_loss: 0.5801 - val_accuracy: 0.8070\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 0.5202 - accuracy: 0.8209 - val_loss: 0.5142 - val_accuracy: 0.8329\n",
      "Epoch 12: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5141649842262268, 0.8329145908355713]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.51\n",
      "accuracy: 83.29%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List the test values of each model you built (0.5 points)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Model\t               Accuracy\t        Loss\n",
    "Baseline\t            0.596\t\n",
    "Cross-sectional\t        94.01\t        0.22\n",
    "deep cross-sectional\t93.47\t        0.28\n",
    "LSTM\t                87.94\t        0.4\n",
    "Deep LSTM\t            90.75\t        0.3\n",
    "GRU model\t            94.26\t        0.19\n",
    "Deep GRU\t            83.29\t        0.51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which model performs the best and why? (0.5 points) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The GRU model is the best model because it is having the highest accuracy of 94.26% and low loss value of 0.19%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does it compare to baseline? (0.5 points)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The baseline test accuracy is 59.6% and GRU model has 94.26%. As the value of test accuracy is more for GRU model it is best model when compare with the baseline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
